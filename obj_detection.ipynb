{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8edNxNTu062a",
        "outputId": "9d6d0305-b09b-4344-b119-f10105bae55e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3691, done.\u001b[K\n",
            "remote: Counting objects: 100% (3691/3691), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3079/3079), done.\u001b[K\n",
            "remote: Total 3691 (delta 990), reused 1509 (delta 561), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3691/3691), 48.75 MiB | 21.13 MiB/s, done.\n",
            "Resolving deltas: 100% (990/990), done.\n"
          ]
        }
      ],
      "source": [
        "# cloning the whole tensorflow/models repository.\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from six.moves.urllib.request import urlopen\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "hytdephxHdLA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  image = None\n",
        "  if(path.startswith('http')):\n",
        "    response = urlopen(path)\n",
        "    image_data = response.read()\n",
        "    image_data = BytesIO(image_data)\n",
        "    image = Image.open(image_data)\n",
        "  else:\n",
        "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "ALL_MODELS = {\n",
        "'CenterNet HourGlass104 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1',\n",
        "'CenterNet HourGlass104 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1',\n",
        "'CenterNet HourGlass104 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1',\n",
        "'CenterNet HourGlass104 Keypoints 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1',\n",
        "'CenterNet Resnet50 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1',\n",
        "'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1',\n",
        "'CenterNet Resnet101 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1',\n",
        "'CenterNet Resnet50 V2 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1',\n",
        "'CenterNet Resnet50 V2 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1',\n",
        "'EfficientDet D0 512x512' : 'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n",
        "'EfficientDet D1 640x640' : 'https://tfhub.dev/tensorflow/efficientdet/d1/1',\n",
        "'EfficientDet D2 768x768' : 'https://tfhub.dev/tensorflow/efficientdet/d2/1',\n",
        "'EfficientDet D3 896x896' : 'https://tfhub.dev/tensorflow/efficientdet/d3/1',\n",
        "'EfficientDet D4 1024x1024' : 'https://tfhub.dev/tensorflow/efficientdet/d4/1',\n",
        "'EfficientDet D5 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d5/1',\n",
        "'EfficientDet D6 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d6/1',\n",
        "'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n",
        "'SSD MobileNet v2 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',\n",
        "'SSD MobileNet V1 FPN 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1',\n",
        "'SSD MobileNet V2 FPNLite 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1',\n",
        "'SSD MobileNet V2 FPNLite 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1',\n",
        "'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1',\n",
        "'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1',\n",
        "'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1',\n",
        "'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1',\n",
        "'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1',\n",
        "'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1',\n",
        "'Faster R-CNN ResNet50 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',\n",
        "'Faster R-CNN ResNet50 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1',\n",
        "'Faster R-CNN ResNet50 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1',\n",
        "'Faster R-CNN ResNet101 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1',\n",
        "'Faster R-CNN ResNet101 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1',\n",
        "'Faster R-CNN ResNet101 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1',\n",
        "'Faster R-CNN ResNet152 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1',\n",
        "'Faster R-CNN ResNet152 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1',\n",
        "'Faster R-CNN ResNet152 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1',\n",
        "'Faster R-CNN Inception ResNet V2 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1',\n",
        "'Faster R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n",
        "'Mask R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'\n",
        "}"
      ],
      "metadata": {
        "id": "3A9j2ghVZiJF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing Object Detection API\n",
        "%%bash\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "IE-8HFEx18RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c52553-5752-47f7-c021-b8f8230a6ddf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "protobuf-compiler is already the newest version (3.6.1.3-2ubuntu5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.45.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.6/14.6 MB 58.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (8.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.5.3)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 352.1/352.1 KB 30.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.11.3-py2.py3-none-any.whl (2.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 82.4 MB/s eta 0:00:00\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.31.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.9/26.9 MB 53.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.11.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 KB 8.2 MB/s eta 0:00:00\n",
            "Collecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.6/116.6 KB 14.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.22.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 58.9 MB/s eta 0:00:00\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 238.9/238.9 KB 24.4 MB/s eta 0:00:00\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 662.4/662.4 KB 48.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.2)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow~=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 KB 4.8 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.72)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting tensorflow-text~=2.11.0\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 97.1 MB/s eta 0:00:00\n",
            "Collecting immutabledict\n",
            "  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 65.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2022.7.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.51.3)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 93.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.0/152.0 KB 20.1 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.7-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.7/140.7 KB 17.0 MB/s eta 0:00:00\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 83.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 526.2/526.2 KB 45.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting objsize<0.7.0,>=0.6.1\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->object-detection==0.1) (23.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.31.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.31.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.14)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.1.21)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.12.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.3)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696872 sha256=2e78e278352c934e3f792cd1019569419dd085c4c9ed0ea3bd752aaef45e043c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3gk4jy8m/wheels/7d/96/c1/072a751379735e8dfdada1def1c62a89afb3cc45654fd6fd28\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=d44d33f26a3269c62ed23f0b427a490072aae3abf18e80619864f9f082dc6898\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=96939a198acd325d2da1cb23bab01691d070a4888c793172bfb62eede73f28fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=858b4cd8e1e800c4632f77bb103497a70ab1826fe7e6106f185edc2bb9959a1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=f9834b61d2ca5173b11838caffe88b65189dfa08e0f2ba57e695f9a3e8695e3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built object-detection avro-python3 dill seqeval docopt\n",
            "Installing collected packages: sentencepiece, py-cpuinfo, docopt, zstandard, tf-slim, tensorflow-model-optimization, tensorflow_io, tensorflow-addons, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, immutabledict, fasteners, fastavro, dill, colorama, avro-python3, sacrebleu, hdfs, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.3\n",
            "    Uninstalling pymongo-4.3.3:\n",
            "      Successfully uninstalled pymongo-4.3.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "Successfully installed apache-beam-2.45.0 avro-python3-1.10.2 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.2 fasteners-0.18 hdfs-2.7.0 immutabledict-2.2.3 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.8.7 portalocker-2.7.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorflow-addons-0.19.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tensorflow_io-0.31.0 tf-models-official-2.11.3 tf-slim-1.1.0 zstandard-0.20.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "jRXeddU82eIq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1Oyfl-Kn4vxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d66e25e-c423-44ce-9a09-2ddc6389330c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video = cv2.VideoCapture('test_1.mp4')"
      ],
      "metadata": {
        "id": "vMcKW7CU5Nl3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting frames from video \n",
        "success=True\n",
        "count=1\n",
        "while success:\n",
        "  success,frame=video.read()\n",
        "  name = '/content/drive/MyDrive/extracted_frames/'+str(count)+'.jpg'\n",
        "  if success==True:\n",
        "    cv2.imwrite(name,frame)\n",
        "    print('Frame {} extracted'.format(count))\n",
        "    count+=1\n",
        "  else:\n",
        "    break\n"
      ],
      "metadata": {
        "id": "tkfU7Zj55aoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c48c50-89c3-4d8a-b7ea-434384154160"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame 1 extracted\n",
            "Frame 2 extracted\n",
            "Frame 3 extracted\n",
            "Frame 4 extracted\n",
            "Frame 5 extracted\n",
            "Frame 6 extracted\n",
            "Frame 7 extracted\n",
            "Frame 8 extracted\n",
            "Frame 9 extracted\n",
            "Frame 10 extracted\n",
            "Frame 11 extracted\n",
            "Frame 12 extracted\n",
            "Frame 13 extracted\n",
            "Frame 14 extracted\n",
            "Frame 15 extracted\n",
            "Frame 16 extracted\n",
            "Frame 17 extracted\n",
            "Frame 18 extracted\n",
            "Frame 19 extracted\n",
            "Frame 20 extracted\n",
            "Frame 21 extracted\n",
            "Frame 22 extracted\n",
            "Frame 23 extracted\n",
            "Frame 24 extracted\n",
            "Frame 25 extracted\n",
            "Frame 26 extracted\n",
            "Frame 27 extracted\n",
            "Frame 28 extracted\n",
            "Frame 29 extracted\n",
            "Frame 30 extracted\n",
            "Frame 31 extracted\n",
            "Frame 32 extracted\n",
            "Frame 33 extracted\n",
            "Frame 34 extracted\n",
            "Frame 35 extracted\n",
            "Frame 36 extracted\n",
            "Frame 37 extracted\n",
            "Frame 38 extracted\n",
            "Frame 39 extracted\n",
            "Frame 40 extracted\n",
            "Frame 41 extracted\n",
            "Frame 42 extracted\n",
            "Frame 43 extracted\n",
            "Frame 44 extracted\n",
            "Frame 45 extracted\n",
            "Frame 46 extracted\n",
            "Frame 47 extracted\n",
            "Frame 48 extracted\n",
            "Frame 49 extracted\n",
            "Frame 50 extracted\n",
            "Frame 51 extracted\n",
            "Frame 52 extracted\n",
            "Frame 53 extracted\n",
            "Frame 54 extracted\n",
            "Frame 55 extracted\n",
            "Frame 56 extracted\n",
            "Frame 57 extracted\n",
            "Frame 58 extracted\n",
            "Frame 59 extracted\n",
            "Frame 60 extracted\n",
            "Frame 61 extracted\n",
            "Frame 62 extracted\n",
            "Frame 63 extracted\n",
            "Frame 64 extracted\n",
            "Frame 65 extracted\n",
            "Frame 66 extracted\n",
            "Frame 67 extracted\n",
            "Frame 68 extracted\n",
            "Frame 69 extracted\n",
            "Frame 70 extracted\n",
            "Frame 71 extracted\n",
            "Frame 72 extracted\n",
            "Frame 73 extracted\n",
            "Frame 74 extracted\n",
            "Frame 75 extracted\n",
            "Frame 76 extracted\n",
            "Frame 77 extracted\n",
            "Frame 78 extracted\n",
            "Frame 79 extracted\n",
            "Frame 80 extracted\n",
            "Frame 81 extracted\n",
            "Frame 82 extracted\n",
            "Frame 83 extracted\n",
            "Frame 84 extracted\n",
            "Frame 85 extracted\n",
            "Frame 86 extracted\n",
            "Frame 87 extracted\n",
            "Frame 88 extracted\n",
            "Frame 89 extracted\n",
            "Frame 90 extracted\n",
            "Frame 91 extracted\n",
            "Frame 92 extracted\n",
            "Frame 93 extracted\n",
            "Frame 94 extracted\n",
            "Frame 95 extracted\n",
            "Frame 96 extracted\n",
            "Frame 97 extracted\n",
            "Frame 98 extracted\n",
            "Frame 99 extracted\n",
            "Frame 100 extracted\n",
            "Frame 101 extracted\n",
            "Frame 102 extracted\n",
            "Frame 103 extracted\n",
            "Frame 104 extracted\n",
            "Frame 105 extracted\n",
            "Frame 106 extracted\n",
            "Frame 107 extracted\n",
            "Frame 108 extracted\n",
            "Frame 109 extracted\n",
            "Frame 110 extracted\n",
            "Frame 111 extracted\n",
            "Frame 112 extracted\n",
            "Frame 113 extracted\n",
            "Frame 114 extracted\n",
            "Frame 115 extracted\n",
            "Frame 116 extracted\n",
            "Frame 117 extracted\n",
            "Frame 118 extracted\n",
            "Frame 119 extracted\n",
            "Frame 120 extracted\n",
            "Frame 121 extracted\n",
            "Frame 122 extracted\n",
            "Frame 123 extracted\n",
            "Frame 124 extracted\n",
            "Frame 125 extracted\n",
            "Frame 126 extracted\n",
            "Frame 127 extracted\n",
            "Frame 128 extracted\n",
            "Frame 129 extracted\n",
            "Frame 130 extracted\n",
            "Frame 131 extracted\n",
            "Frame 132 extracted\n",
            "Frame 133 extracted\n",
            "Frame 134 extracted\n",
            "Frame 135 extracted\n",
            "Frame 136 extracted\n",
            "Frame 137 extracted\n",
            "Frame 138 extracted\n",
            "Frame 139 extracted\n",
            "Frame 140 extracted\n",
            "Frame 141 extracted\n",
            "Frame 142 extracted\n",
            "Frame 143 extracted\n",
            "Frame 144 extracted\n",
            "Frame 145 extracted\n",
            "Frame 146 extracted\n",
            "Frame 147 extracted\n",
            "Frame 148 extracted\n",
            "Frame 149 extracted\n",
            "Frame 150 extracted\n",
            "Frame 151 extracted\n",
            "Frame 152 extracted\n",
            "Frame 153 extracted\n",
            "Frame 154 extracted\n",
            "Frame 155 extracted\n",
            "Frame 156 extracted\n",
            "Frame 157 extracted\n",
            "Frame 158 extracted\n",
            "Frame 159 extracted\n",
            "Frame 160 extracted\n",
            "Frame 161 extracted\n",
            "Frame 162 extracted\n",
            "Frame 163 extracted\n",
            "Frame 164 extracted\n",
            "Frame 165 extracted\n",
            "Frame 166 extracted\n",
            "Frame 167 extracted\n",
            "Frame 168 extracted\n",
            "Frame 169 extracted\n",
            "Frame 170 extracted\n",
            "Frame 171 extracted\n",
            "Frame 172 extracted\n",
            "Frame 173 extracted\n",
            "Frame 174 extracted\n",
            "Frame 175 extracted\n",
            "Frame 176 extracted\n",
            "Frame 177 extracted\n",
            "Frame 178 extracted\n",
            "Frame 179 extracted\n",
            "Frame 180 extracted\n",
            "Frame 181 extracted\n",
            "Frame 182 extracted\n",
            "Frame 183 extracted\n",
            "Frame 184 extracted\n",
            "Frame 185 extracted\n",
            "Frame 186 extracted\n",
            "Frame 187 extracted\n",
            "Frame 188 extracted\n",
            "Frame 189 extracted\n",
            "Frame 190 extracted\n",
            "Frame 191 extracted\n",
            "Frame 192 extracted\n",
            "Frame 193 extracted\n",
            "Frame 194 extracted\n",
            "Frame 195 extracted\n",
            "Frame 196 extracted\n",
            "Frame 197 extracted\n",
            "Frame 198 extracted\n",
            "Frame 199 extracted\n",
            "Frame 200 extracted\n",
            "Frame 201 extracted\n",
            "Frame 202 extracted\n",
            "Frame 203 extracted\n",
            "Frame 204 extracted\n",
            "Frame 205 extracted\n",
            "Frame 206 extracted\n",
            "Frame 207 extracted\n",
            "Frame 208 extracted\n",
            "Frame 209 extracted\n",
            "Frame 210 extracted\n",
            "Frame 211 extracted\n",
            "Frame 212 extracted\n",
            "Frame 213 extracted\n",
            "Frame 214 extracted\n",
            "Frame 215 extracted\n",
            "Frame 216 extracted\n",
            "Frame 217 extracted\n",
            "Frame 218 extracted\n",
            "Frame 219 extracted\n",
            "Frame 220 extracted\n",
            "Frame 221 extracted\n",
            "Frame 222 extracted\n",
            "Frame 223 extracted\n",
            "Frame 224 extracted\n",
            "Frame 225 extracted\n",
            "Frame 226 extracted\n",
            "Frame 227 extracted\n",
            "Frame 228 extracted\n",
            "Frame 229 extracted\n",
            "Frame 230 extracted\n",
            "Frame 231 extracted\n",
            "Frame 232 extracted\n",
            "Frame 233 extracted\n",
            "Frame 234 extracted\n",
            "Frame 235 extracted\n",
            "Frame 236 extracted\n",
            "Frame 237 extracted\n",
            "Frame 238 extracted\n",
            "Frame 239 extracted\n",
            "Frame 240 extracted\n",
            "Frame 241 extracted\n",
            "Frame 242 extracted\n",
            "Frame 243 extracted\n",
            "Frame 244 extracted\n",
            "Frame 245 extracted\n",
            "Frame 246 extracted\n",
            "Frame 247 extracted\n",
            "Frame 248 extracted\n",
            "Frame 249 extracted\n",
            "Frame 250 extracted\n",
            "Frame 251 extracted\n",
            "Frame 252 extracted\n",
            "Frame 253 extracted\n",
            "Frame 254 extracted\n",
            "Frame 255 extracted\n",
            "Frame 256 extracted\n",
            "Frame 257 extracted\n",
            "Frame 258 extracted\n",
            "Frame 259 extracted\n",
            "Frame 260 extracted\n",
            "Frame 261 extracted\n",
            "Frame 262 extracted\n",
            "Frame 263 extracted\n",
            "Frame 264 extracted\n",
            "Frame 265 extracted\n",
            "Frame 266 extracted\n",
            "Frame 267 extracted\n",
            "Frame 268 extracted\n",
            "Frame 269 extracted\n",
            "Frame 270 extracted\n",
            "Frame 271 extracted\n",
            "Frame 272 extracted\n",
            "Frame 273 extracted\n",
            "Frame 274 extracted\n",
            "Frame 275 extracted\n",
            "Frame 276 extracted\n",
            "Frame 277 extracted\n",
            "Frame 278 extracted\n",
            "Frame 279 extracted\n",
            "Frame 280 extracted\n",
            "Frame 281 extracted\n",
            "Frame 282 extracted\n",
            "Frame 283 extracted\n",
            "Frame 284 extracted\n",
            "Frame 285 extracted\n",
            "Frame 286 extracted\n",
            "Frame 287 extracted\n",
            "Frame 288 extracted\n",
            "Frame 289 extracted\n",
            "Frame 290 extracted\n",
            "Frame 291 extracted\n",
            "Frame 292 extracted\n",
            "Frame 293 extracted\n",
            "Frame 294 extracted\n",
            "Frame 295 extracted\n",
            "Frame 296 extracted\n",
            "Frame 297 extracted\n",
            "Frame 298 extracted\n",
            "Frame 299 extracted\n",
            "Frame 300 extracted\n",
            "Frame 301 extracted\n",
            "Frame 302 extracted\n",
            "Frame 303 extracted\n",
            "Frame 304 extracted\n",
            "Frame 305 extracted\n",
            "Frame 306 extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name='/content/drive/MyDrive/extracted_frames/'\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "gMeedUXl-hm5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "category_index"
      ],
      "metadata": {
        "id": "aVmNeL5iBcrM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9000bc-f16b-46e6-ac8b-053e839b8fb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'id': 1, 'name': 'person'},\n",
              " 2: {'id': 2, 'name': 'bicycle'},\n",
              " 3: {'id': 3, 'name': 'car'},\n",
              " 4: {'id': 4, 'name': 'motorcycle'},\n",
              " 5: {'id': 5, 'name': 'airplane'},\n",
              " 6: {'id': 6, 'name': 'bus'},\n",
              " 7: {'id': 7, 'name': 'train'},\n",
              " 8: {'id': 8, 'name': 'truck'},\n",
              " 9: {'id': 9, 'name': 'boat'},\n",
              " 10: {'id': 10, 'name': 'traffic light'},\n",
              " 11: {'id': 11, 'name': 'fire hydrant'},\n",
              " 13: {'id': 13, 'name': 'stop sign'},\n",
              " 14: {'id': 14, 'name': 'parking meter'},\n",
              " 15: {'id': 15, 'name': 'bench'},\n",
              " 16: {'id': 16, 'name': 'bird'},\n",
              " 17: {'id': 17, 'name': 'cat'},\n",
              " 18: {'id': 18, 'name': 'dog'},\n",
              " 19: {'id': 19, 'name': 'horse'},\n",
              " 20: {'id': 20, 'name': 'sheep'},\n",
              " 21: {'id': 21, 'name': 'cow'},\n",
              " 22: {'id': 22, 'name': 'elephant'},\n",
              " 23: {'id': 23, 'name': 'bear'},\n",
              " 24: {'id': 24, 'name': 'zebra'},\n",
              " 25: {'id': 25, 'name': 'giraffe'},\n",
              " 27: {'id': 27, 'name': 'backpack'},\n",
              " 28: {'id': 28, 'name': 'umbrella'},\n",
              " 31: {'id': 31, 'name': 'handbag'},\n",
              " 32: {'id': 32, 'name': 'tie'},\n",
              " 33: {'id': 33, 'name': 'suitcase'},\n",
              " 34: {'id': 34, 'name': 'frisbee'},\n",
              " 35: {'id': 35, 'name': 'skis'},\n",
              " 36: {'id': 36, 'name': 'snowboard'},\n",
              " 37: {'id': 37, 'name': 'sports ball'},\n",
              " 38: {'id': 38, 'name': 'kite'},\n",
              " 39: {'id': 39, 'name': 'baseball bat'},\n",
              " 40: {'id': 40, 'name': 'baseball glove'},\n",
              " 41: {'id': 41, 'name': 'skateboard'},\n",
              " 42: {'id': 42, 'name': 'surfboard'},\n",
              " 43: {'id': 43, 'name': 'tennis racket'},\n",
              " 44: {'id': 44, 'name': 'bottle'},\n",
              " 46: {'id': 46, 'name': 'wine glass'},\n",
              " 47: {'id': 47, 'name': 'cup'},\n",
              " 48: {'id': 48, 'name': 'fork'},\n",
              " 49: {'id': 49, 'name': 'knife'},\n",
              " 50: {'id': 50, 'name': 'spoon'},\n",
              " 51: {'id': 51, 'name': 'bowl'},\n",
              " 52: {'id': 52, 'name': 'banana'},\n",
              " 53: {'id': 53, 'name': 'apple'},\n",
              " 54: {'id': 54, 'name': 'sandwich'},\n",
              " 55: {'id': 55, 'name': 'orange'},\n",
              " 56: {'id': 56, 'name': 'broccoli'},\n",
              " 57: {'id': 57, 'name': 'carrot'},\n",
              " 58: {'id': 58, 'name': 'hot dog'},\n",
              " 59: {'id': 59, 'name': 'pizza'},\n",
              " 60: {'id': 60, 'name': 'donut'},\n",
              " 61: {'id': 61, 'name': 'cake'},\n",
              " 62: {'id': 62, 'name': 'chair'},\n",
              " 63: {'id': 63, 'name': 'couch'},\n",
              " 64: {'id': 64, 'name': 'potted plant'},\n",
              " 65: {'id': 65, 'name': 'bed'},\n",
              " 67: {'id': 67, 'name': 'dining table'},\n",
              " 70: {'id': 70, 'name': 'toilet'},\n",
              " 72: {'id': 72, 'name': 'tv'},\n",
              " 73: {'id': 73, 'name': 'laptop'},\n",
              " 74: {'id': 74, 'name': 'mouse'},\n",
              " 75: {'id': 75, 'name': 'remote'},\n",
              " 76: {'id': 76, 'name': 'keyboard'},\n",
              " 77: {'id': 77, 'name': 'cell phone'},\n",
              " 78: {'id': 78, 'name': 'microwave'},\n",
              " 79: {'id': 79, 'name': 'oven'},\n",
              " 80: {'id': 80, 'name': 'toaster'},\n",
              " 81: {'id': 81, 'name': 'sink'},\n",
              " 82: {'id': 82, 'name': 'refrigerator'},\n",
              " 84: {'id': 84, 'name': 'book'},\n",
              " 85: {'id': 85, 'name': 'clock'},\n",
              " 86: {'id': 86, 'name': 'vase'},\n",
              " 87: {'id': 87, 'name': 'scissors'},\n",
              " 88: {'id': 88, 'name': 'teddy bear'},\n",
              " 89: {'id': 89, 'name': 'hair drier'},\n",
              " 90: {'id': 90, 'name': 'toothbrush'}}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Selection { display-mode: \"form\", run: \"auto\" }\n",
        "model_display_name = 'Faster R-CNN Inception ResNet V2 1024x1024' # @param ['CenterNet HourGlass104 512x512','CenterNet HourGlass104 Keypoints 512x512','CenterNet HourGlass104 1024x1024','CenterNet HourGlass104 Keypoints 1024x1024','CenterNet Resnet50 V1 FPN 512x512','CenterNet Resnet50 V1 FPN Keypoints 512x512','CenterNet Resnet101 V1 FPN 512x512','CenterNet Resnet50 V2 512x512','CenterNet Resnet50 V2 Keypoints 512x512','EfficientDet D0 512x512','EfficientDet D1 640x640','EfficientDet D2 768x768','EfficientDet D3 896x896','EfficientDet D4 1024x1024','EfficientDet D5 1280x1280','EfficientDet D6 1280x1280','EfficientDet D7 1536x1536','SSD MobileNet v2 320x320','SSD MobileNet V1 FPN 640x640','SSD MobileNet V2 FPNLite 320x320','SSD MobileNet V2 FPNLite 640x640','SSD ResNet50 V1 FPN 640x640 (RetinaNet50)','SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)','SSD ResNet101 V1 FPN 640x640 (RetinaNet101)','SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)','SSD ResNet152 V1 FPN 640x640 (RetinaNet152)','SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)','Faster R-CNN ResNet50 V1 640x640','Faster R-CNN ResNet50 V1 1024x1024','Faster R-CNN ResNet50 V1 800x1333','Faster R-CNN ResNet101 V1 640x640','Faster R-CNN ResNet101 V1 1024x1024','Faster R-CNN ResNet101 V1 800x1333','Faster R-CNN ResNet152 V1 640x640','Faster R-CNN ResNet152 V1 1024x1024','Faster R-CNN ResNet152 V1 800x1333','Faster R-CNN Inception ResNet V2 640x640','Faster R-CNN Inception ResNet V2 1024x1024','Mask R-CNN Inception ResNet V2 1024x1024']\n",
        "model_handle = ALL_MODELS[model_display_name]\n",
        "\n",
        "print('Selected model:'+ model_display_name)\n",
        "print('Model Handle at TensorFlow Hub: {}'.format(model_handle))"
      ],
      "metadata": {
        "id": "1VRvJrJDT4n9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c1d576-5fb5-49ae-8753-cb7f5bf10bd6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected model:Faster R-CNN Inception ResNet V2 1024x1024\n",
            "Model Handle at TensorFlow Hub: https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "print('loading model...')\n",
        "hub_model = hub.load(model_handle)\n",
        "print('model loaded!')"
      ],
      "metadata": {
        "id": "bVui_JwwX4wB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2a1e60-646a-4a23-c763-92f1792db331"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model...\n",
            "model loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "for filename in os.listdir('/content/drive/MyDrive/extracted_frames/'):\n",
        "  if filename.endswith(\"jpg\"):\n",
        "    x='/content/drive/MyDrive/extracted_frames/'+filename\n",
        "    image_np = load_image_into_numpy_array(x)\n",
        "    results = hub_model(image_np)\n",
        "    result = {key:value.numpy() for key,value in results.items()}\n",
        "    label_id_offset = 0\n",
        "    image_np_with_detections = image_np.copy()\n",
        "    # Use keypoints if available in detections\n",
        "    keypoints, keypoint_scores = None, None\n",
        "    if 'detection_keypoints' in result:\n",
        "      keypoints = result['detection_keypoints'][0]\n",
        "      keypoint_scores = result['detection_keypoint_scores'][0]\n",
        "    \n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections[0],\n",
        "        result['detection_boxes'][0],\n",
        "        (result['detection_classes'][0] + label_id_offset).astype(int),\n",
        "        result['detection_scores'][0],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=.30,\n",
        "        agnostic_mode=False,\n",
        "        keypoints=keypoints,\n",
        "        keypoint_scores=keypoint_scores)\n",
        "    \n",
        "    image = Image.fromarray(image_np_with_detections[0])\n",
        "    image.save('/content/drive/MyDrive/extracted_frames_with_detection/'+filename, 'JPEG')\n"
      ],
      "metadata": {
        "id": "a2G9anHbDLcf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "image_folder = '/content/drive/MyDrive/extracted_frames_with_detection/'\n",
        "video_name = 'video.avi'\n",
        "\n",
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), 60, (width,height))\n",
        "\n",
        "for image in images:\n",
        "  video.write(cv2.imread(os.path.join(image_folder, image)))\n",
        "\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()\n",
        "#final output is in .avi. Converted to .mp4."
      ],
      "metadata": {
        "id": "kfvAe7l10Cku"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}